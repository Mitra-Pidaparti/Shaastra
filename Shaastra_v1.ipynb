{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juf3NUtue7Jv"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOyuJ_AWlxJ8"
      },
      "outputs": [],
      "source": [
        "# creating function to get numpy arrays of images and corresponding labels\n",
        "\n",
        "def generate_data(use):\n",
        "    use_data = os.path.join(\"..\", \"archive\", use)\n",
        "    \n",
        "    use_pos = os.listdir(os.path.join(use_data, \"Positive\"))\n",
        "    use_neg = os.listdir(os.path.join(use_data, \"Negative\"))\n",
        "    pos_imgs = [cv2.imread(os.path.join(use_data, \"Positive\", x)) for x in use_pos]\n",
        "    neg_imgs = [cv2.imread(os.path.join(use_data, \"Negative\", x)) for x in use_neg]\n",
        "    use_imgs = []\n",
        "    labels = []\n",
        "\n",
        "    for img in pos_imgs:\n",
        "        use_imgs.append(img)\n",
        "        labels.append(1)\n",
        "\n",
        "    for img in neg_imgs:\n",
        "        use_imgs.append(img)\n",
        "        labels.append(0)\n",
        "        \n",
        "    use_imgs = np.array(use_imgs) / 255.0\n",
        "    labels = np.array(labels)\n",
        "        \n",
        "    return (use_imgs, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajo4nc49H0rq"
      },
      "outputs": [],
      "source": [
        "#creating train and validation numpy arrays of images and labels\n",
        "\n",
        "train_imgs, train_labels = generate_data(\"train\")\n",
        "valid_imgs, valid_labels = generate_data(\"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYMiAiONH3ny"
      },
      "outputs": [],
      "source": [
        "#shuffling the train and validation datasets so that poitive and negative labelled images intermix randomly\n",
        "\n",
        "def shuffle_together(a, b):\n",
        "    a = list(a); b = list(b)\n",
        "    dset = []; X = []; Y = []\n",
        "    if (len(a) == len(b)):\n",
        "        length = len(a)\n",
        "    else:\n",
        "        return (0, 0)\n",
        "    c = zip(a, b)\n",
        "    \n",
        "    for item in c:\n",
        "        dset.append(item)\n",
        "    dset = np.array(dset)\n",
        "    np.random.shuffle(dset)\n",
        "    \n",
        "    for item in dset:\n",
        "        X.append(item[0])\n",
        "        Y.append(item[1])\n",
        "        \n",
        "    X = np.array(X); Y = np.array(Y)\n",
        "    \n",
        "    return (X, Y)\n",
        "\n",
        "train_imgs, train_labels = shuffle_together(train_imgs, train_labels)\n",
        "valid_imgs, valid_labels = shuffle_together(valid_imgs, valid_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVq9qiYHIrsk"
      },
      "outputs": [],
      "source": [
        "# importing tensorflow for creating neural network\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YT7lB6WCQ2i_"
      },
      "outputs": [],
      "source": [
        "# Making custom function for image augmentation\n",
        "\n",
        "def augment(image, label):\n",
        "    # sizing to a standard size\n",
        "    new_height = 224\n",
        "    new_width = 224\n",
        "    image = tf.image.resize(image, (new_height, new_width))\n",
        "    \n",
        "    # changing color-scheme randomly\n",
        "    if tf.random.uniform((), minval = 0, maxval = 1) <= 0.1:\n",
        "        image = tf.tile(tf.image.rgb_to_grayscale(image), [1, 1, 3])\n",
        "        \n",
        "    # randomly allotting brightness level\n",
        "    image = tf.image.random_brightness(image, max_delta = 0.5)\n",
        "    \n",
        "    # flipping horizontally - 50% of the times\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    \n",
        "    # rotating\n",
        "    image = tf.image.rot90(image, k = int(tf.random.uniform((), minval = 0, maxval = 4)))\n",
        "    \n",
        "    return np.array(image), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txcacXqSRAto"
      },
      "outputs": [],
      "source": [
        "# This will generate an array containing augmented images from the train set supplied as input variable\n",
        "\n",
        "def augmented_set(use_imgs, labels, k = 2):\n",
        "    use_set = zip(list(use_imgs), list(labels))\n",
        "    new_set = []\n",
        "    \n",
        "    for point in use_set:\n",
        "        for i in range(k):\n",
        "            new_img, new_label = augment(point[0], point[1])\n",
        "            new_set.append((new_img, new_label))\n",
        "    \n",
        "    new_imgs = [point[0] for point in new_set]\n",
        "    new_labels = [point[1] for point in new_set]\n",
        "    \n",
        "    return np.array(new_imgs, dtype = object), np.array(new_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWsnSGOiReKi"
      },
      "outputs": [],
      "source": [
        "# getting the augmented dataset from the train set created above\n",
        "\n",
        "dtrain_imgs, dtrain_labels = augmented_set(train_imgs, train_labels, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs7eEQVBI3WV"
      },
      "outputs": [],
      "source": [
        "# creating neural network\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation = \"relu\", input_shape = (224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation = \"relu\"),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation = \"relu\"),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation = \"relu\"),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation = \"relu\"),\n",
        "    Dense(1, activation = \"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4sNlM2_I9Fw"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = \"binary_crossentropy\", optimizer = \"Adam\", metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6IAyjUvJByj",
        "outputId": "6b40e276-28c6-48df-ccc6-9bfe7408c39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 111, 111, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 109, 109, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 54, 54, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 52, 52, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 26, 26, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 12, 12, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 18432)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               2359424   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,462,049\n",
            "Trainable params: 2,462,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBnddEQ3RxFZ"
      },
      "outputs": [],
      "source": [
        "dtrain_labels = np.asarray(dtrain_labels).astype(\"float32\")\n",
        "dtrain_imgs = np.asarray(dtrain_imgs).astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GBizcTtJE8L",
        "outputId": "9a67fdea-4b04-44f2-a06a-b1e66c446e81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 0.6930 - accuracy: 0.5566 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
            "Epoch 2/12\n",
            "149/149 [==============================] - 16s 109ms/step - loss: 0.6920 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/12\n",
            "149/149 [==============================] - 15s 101ms/step - loss: 0.6849 - accuracy: 0.5365 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
            "Epoch 4/12\n",
            "149/149 [==============================] - 16s 108ms/step - loss: 0.6407 - accuracy: 0.6086 - val_loss: 0.6917 - val_accuracy: 0.5150\n",
            "Epoch 5/12\n",
            "149/149 [==============================] - 18s 118ms/step - loss: 0.6691 - accuracy: 0.5772 - val_loss: 0.6360 - val_accuracy: 0.8650\n",
            "Epoch 6/12\n",
            "149/149 [==============================] - 18s 120ms/step - loss: 0.5447 - accuracy: 0.7303 - val_loss: 0.4686 - val_accuracy: 0.8350\n",
            "Epoch 7/12\n",
            "149/149 [==============================] - 18s 121ms/step - loss: 0.3961 - accuracy: 0.8356 - val_loss: 0.2101 - val_accuracy: 0.9400\n",
            "Epoch 8/12\n",
            "149/149 [==============================] - 18s 118ms/step - loss: 0.2201 - accuracy: 0.9224 - val_loss: 0.2352 - val_accuracy: 0.9150\n",
            "Epoch 9/12\n",
            "149/149 [==============================] - 16s 107ms/step - loss: 0.1436 - accuracy: 0.9509 - val_loss: 0.3251 - val_accuracy: 0.8900\n",
            "Epoch 10/12\n",
            "149/149 [==============================] - 15s 104ms/step - loss: 0.1086 - accuracy: 0.9673 - val_loss: 0.4992 - val_accuracy: 0.8650\n",
            "Epoch 11/12\n",
            "149/149 [==============================] - 17s 114ms/step - loss: 0.0617 - accuracy: 0.9803 - val_loss: 0.2540 - val_accuracy: 0.9400\n",
            "Epoch 12/12\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 0.0395 - accuracy: 0.9908 - val_loss: 0.3413 - val_accuracy: 0.9400\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x18e6f6ecb80>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# training on train dataset\n",
        "\n",
        "model.fit(dtrain_imgs, dtrain_labels, batch_size = 16, epochs = 12, validation_data = (valid_imgs, valid_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiLmnd6uJIqj",
        "outputId": "29152881-0f42-4326-f63c-d669a56f801f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 28ms/step - loss: 0.0307 - accuracy: 1.0000\n",
            "test loss, test accuracy:  [0.030655747279524803, 1.0]\n"
          ]
        }
      ],
      "source": [
        "test_imgs, test_labels = generate_data(\"test\")\n",
        "res = model.evaluate(test_imgs, test_labels, batch_size = 16)\n",
        "print(\"test loss, test accuracy: \", res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fISZjUsw3HF5",
        "outputId": "5a428737-8c9f-4e25-e3ab-b7a79fc1db19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n"
          ]
        }
      ],
      "source": [
        "pred_labels = []\n",
        "\n",
        "for test_img in test_imgs:\n",
        "    test_img = test_img.reshape((1, ) + test_img.shape)\n",
        "    prediction = model.predict(test_img)\n",
        "    \n",
        "    if (prediction[0][0] > 0.5):\n",
        "        pred_labels.append(1)\n",
        "    else:\n",
        "        pred_labels.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBjQcfk73UFK"
      },
      "outputs": [],
      "source": [
        "conf = np.array(tf.math.confusion_matrix(np.array(test_labels), np.array(pred_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLAK6wxEBKOt",
        "outputId": "d9f0d7ab-1581-41a2-abbb-2789e6eb14c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[100,   0],\n",
              "       [  0, 100]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo70lGWY3Y_Z",
        "outputId": "c80bcbf1-0092-4722-82f5-2c2f654fe8b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision:  1.0  recall:  1.0  F1:  1.0\n"
          ]
        }
      ],
      "source": [
        "precision_score = conf[0][0] / (conf[0][0] + conf[0][1])\n",
        "recall = conf[0][0] / (conf[0][0] + conf[1][0])\n",
        "\n",
        "f1_score = (2 * precision_score * recall) / (precision_score + recall)\n",
        "\n",
        "print(\"precision: \", precision_score, \" recall: \", recall, \" F1: \", f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wurMeKxJe_m2"
      },
      "outputs": [],
      "source": [
        "# to predict on any image of any dimensions and having crack at any location in the image\n",
        "\n",
        "def predict_any_image(img_path, model):\n",
        "    img = cv2.imread(img_path) / 255.0\n",
        "    img_ht = img.shape[0]\n",
        "    img_wt = img.shape[1]\n",
        "\n",
        "    # this variable will become 1 when crack is found in image\n",
        "    done = 0\n",
        "    \n",
        "    # if dimensions of image are less than (224, 224) then reshaping to increase size to 224\n",
        "    if (img_ht < 224):\n",
        "        img = cv2.resize(img, (224, img.shape[1]))\n",
        "    if (img_wt < 224):\n",
        "        img = cv2.resize(img, (img.shape[0], 224))\n",
        "        \n",
        "    # if image is now of exact dimension as required, simply predict using the model and print result, then exit the function\n",
        "    if (img.shape == (224, 224, 3)):\n",
        "        img = img.reshape((1, ) + img.shape)\n",
        "        pred = model.predict(img, verbose = 3)\n",
        "        if (pred[0][0] > 0.5):\n",
        "            print(\"Cracked\")\n",
        "            return\n",
        "        else:\n",
        "            print(\"Not-Cracked\")\n",
        "            return\n",
        "    \n",
        "    # if any dimension of image is now > 336 then begin looping with a window of 224 x 224 and check if crack found\n",
        "    if (img.shape[0] > 336 or img.shape[1] > 336):\n",
        "        \n",
        "        # \"l\" variable is used to shift the window along height of image and \"k\" to shift along width\n",
        "        l = k = 0\n",
        "\n",
        "        # loop till we don't reach the bottom of the image\n",
        "        while (l + 224 <= img.shape[0]):\n",
        "            k = 0\n",
        "\n",
        "            # at a particular value of l i.e at a particular height of the window loop on variable \"k\" to shift window along width of image\n",
        "            while (k + 224 <= img.shape[1]):\n",
        "\n",
        "                # creating a window named img_sub of size 224 x 224\n",
        "                img_sub = img[l: l + 224, k: k + 224]\n",
        "\n",
        "                # reshaping window to the dimensions as required by the neural network\n",
        "                img_sub = img_sub.reshape((1, ) + img_sub.shape)\n",
        "\n",
        "                # making predictions\n",
        "                pred = model.predict(img_sub, verbose = 3)\n",
        "                if (pred[0][0] > 0.5):\n",
        "                    print(\"Cracked\")\n",
        "                    done = 1\n",
        "                    return\n",
        "                else:\n",
        "                    # if not found then update \"k\" to shift window by 112 units along the width of the image\n",
        "                    k += 112\n",
        "            \n",
        "            # when full width checked of image at particular height, shift window downwards by 112 units\n",
        "            l += 112\n",
        "    else:\n",
        "        # if image is not that big then simple resizing wouldn't harm the image quality much so simply resize and predict\n",
        "        img = cv2.resize(img, (224, 224, 3))\n",
        "        \n",
        "        pred = model.predict(img, verbose = 3)\n",
        "        if (pred[0][0] > 0.5):\n",
        "            print(\"Cracked\")\n",
        "            return\n",
        "        else:\n",
        "            print(\"Not-Cracked\")\n",
        "            return\n",
        "    \n",
        "    # done is still 0 i.e. crack is not found so, print \"Not-Cracked\" and exit function\n",
        "    if (done == 0):\n",
        "        print(\"Not-Cracked\")\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGyT3yKZpJSd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}